<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>artifact evaluation on Anjo Vahldiek-Oberwagner</title>
    <link>https://vahldiek.github.io/tags/artifact-evaluation/</link>
    <description>Recent content in artifact evaluation on Anjo Vahldiek-Oberwagner</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 05 Jul 2022 00:24:42 +0100</lastBuildDate>
    
	<atom:link href="https://vahldiek.github.io/tags/artifact-evaluation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Research Artifacts and Evaluation</title>
      <link>https://vahldiek.github.io/project/artifact-eval/</link>
      <pubDate>Tue, 05 Jul 2022 00:24:42 +0100</pubDate>
      
      <guid>https://vahldiek.github.io/project/artifact-eval/</guid>
      <description>A scientific paper consists of a constellation of artifacts that extend beyond the document itself: software, hardware, evaluation data and documentation, raw survey results, mechanized proofs, models, test suites, benchmarks, and so on. In some cases, the quality of these artifacts is as important as that of the document itself.
My involvement in artifact evaluation efforts in the systems, security and HPC communities have led to a growing understanding of building reusable and reproducible artifacts.</description>
    </item>
    
  </channel>
</rss>